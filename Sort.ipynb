{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "waiting-northern",
   "metadata": {},
   "source": [
    "## Sort a list using a neural network\n",
    "\n",
    "Input: A list of numbers.\n",
    "\n",
    "Output: A sorted list of the same numbers.\n",
    "\n",
    "Treat the list as a fully connected directed graph where each node represents a number.\n",
    "Use binary labels on the edges to encode a sorted path from the smallest to the largest number, i.e. the network should predict a starting node and the links to the next elements in a sorted linked list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "basic-fiction",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "another-printing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs: {'nodes': array([0.9954747 , 0.19633869, 0.74219906, 0.26312504, 0.79240632,\n",
      "       0.61373669, 0.90991295])}\n",
      "targets: {'start_node': array([0., 1., 0., 0., 0., 0., 0.]), 'next_nodes': array([[0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0.]])}\n",
      "sort indices: [1 3 5 2 4 6 0]\n"
     ]
    }
   ],
   "source": [
    "def make_example(min_max):\n",
    "    num_elements = np.random.randint(min_max[0], min_max[1])\n",
    "    values = np.random.rand(num_elements)\n",
    "    sort_indices = np.argsort(values, axis=-1)\n",
    "    smallest = np.eye(num_elements)[sort_indices[0]]\n",
    "    links = np.zeros((num_elements, num_elements))\n",
    "    links[sort_indices[:-1], sort_indices[1:]] = 1\n",
    "    links[sort_indices[-1], sort_indices[0]] = 1\n",
    "    input_graph = {\"nodes\" : values}\n",
    "    target_graph = {\"start_node\" : smallest,\n",
    "                   \"next_nodes\" : links}\n",
    "    return input_graph, target_graph, sort_indices\n",
    "\n",
    "input_graph, target_graph, sort_indices = make_example((7,8))\n",
    "print(\"inputs:\",input_graph)\n",
    "print(\"targets:\",target_graph)\n",
    "print(\"sort indices:\",sort_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "scenic-least",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_numbers(ax, next_nodes, sort_indices):\n",
    "    ax.matshow(next_nodes[sort_indices][:, sort_indices], cmap=\"viridis\")\n",
    "    ax.grid(False)\n",
    "    \n",
    "fig = plt.figure(1, figsize=(4, 4))\n",
    "ax = fig.add_subplot()\n",
    "plot_numbers(ax, target_graph[\"next_nodes\"], sort_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "proud-minute",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_NODES_TRAIN = (100,150)\n",
    "NUM_NODES_VAL = (250,300)\n",
    "\n",
    "class SampleGenerator(keras.utils.Sequence):\n",
    "\n",
    "    def __init__(self, num_minmax, epoch_len):\n",
    "        self.num_minmax = num_minmax\n",
    "        self.epoch_len = epoch_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.epoch_len #number of gradient descent steps per epoch\n",
    "\n",
    "    def __getitem__(self, _index):\n",
    "        inp, tar, _ = make_example(self.num_minmax)\n",
    "        return inp, tar\n",
    "    \n",
    "\n",
    "train_gen = SampleGenerator(NUM_NODES_TRAIN, 1000)\n",
    "val_gen = SampleGenerator(NUM_NODES_VAL, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assisted-mediterranean",
   "metadata": {},
   "source": [
    "Define a model. We only have node inputs which are the numbers to sort. For each node, we want to predict the probability of being the \"start\" node (i.e. the node with the smallest number). For each edge we want to predict successor in a sorted linked list. We use a very simple GNN with only node states. Edge predictions are done on pairs of node states. \n",
    "\n",
    "We don't use global attributes for in- and output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cooked-muslim",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a feedforward layer\n",
    "def make_ff_layer(config):\n",
    "    return keras.Sequential([\n",
    "            layers.Dense(config[\"latent_dim\"], activation=\"relu\"),\n",
    "            layers.Dense(config[\"latent_dim\"]),\n",
    "            layers.LayerNormalization()])\n",
    "\n",
    "def make_GNN(config):\n",
    "    \n",
    "    #define the inputs\n",
    "    #note: keras inputs have their batch size omitted in \"shape\"\n",
    "    V = keras.Input(shape=(1), name=\"nodes\") \n",
    "    \n",
    "    n = tf.shape(V)[0]\n",
    "    \n",
    "    #step 1: encode\n",
    "    #transform each node (dim=3) and edge (dim=1) to a latent embedding of \"latent_dim\"\n",
    "    node_encoder = make_ff_layer(config)\n",
    "    V_enc = node_encoder(V)\n",
    "    \n",
    "    #step 2: message passing\n",
    "    node_messager = make_ff_layer(config)\n",
    "    node_updater = make_ff_layer(config)\n",
    "    for _ in range(config[\"message_passing_iterations\"]):\n",
    "        \n",
    "        #the graph is fully connected, i.e. each node sends \n",
    "        #to all other nodes except itself \n",
    "        V_message = node_messager(V_enc)\n",
    "        V_message = (tf.reduce_sum(V_message, axis=0, keepdims=True) - V_message) \n",
    "        V_message /= tf.cast(n-1, dtype=V_message.dtype)\n",
    "        \n",
    "        #update all nodes based on current state and aggregated edge states\n",
    "        V_concat = tf.concat([V_enc, V_message], axis=-1)\n",
    "        V_enc = node_updater(V_concat)\n",
    "        \n",
    "    #step 3: decode\n",
    "    \n",
    "    #layers\n",
    "    node_decoder = layers.Dense(1)\n",
    "    edge_decoder = keras.Sequential([\n",
    "            layers.Dense(config[\"latent_dim\"], activation=\"relu\"),\n",
    "            layers.Dense(1)])\n",
    "    \n",
    "    #in this case, we need node and edge predictions\n",
    "    #for nodes, use the refined embeddings from message passing above:\n",
    "    start_node_probs = node_decoder(V_enc)\n",
    "    #remove \"1\" dimensions\n",
    "    start_node_probs = tf.squeeze(start_node_probs)\n",
    "    #decide for one start node\n",
    "    start_node_probs = tf.nn.softmax(start_node_probs) \n",
    "    \n",
    "    #for edges, use the respective pair of node embeddings (we did not use explicit edge embeddings)\n",
    "    #organize edges as follows:\n",
    "    #<n edges from v_1>, <n edges from v_2>, ..., <n edges from v_n>\n",
    "    #we do not exclude self loops for simplicity\n",
    "    V_tile = tf.tile(V_enc, [n,1]) #abc -> (abc abc ... abc) \n",
    "    V_rep = tf.repeat(V_enc, tf.ones(n,dtype=tf.int32)*n, axis=0) #abc -> (aa..a  bb..b  cc..c) \n",
    "    next_node_probs = edge_decoder(tf.concat([V_tile, V_rep], axis=-1))\n",
    "    next_node_probs = tf.reshape(next_node_probs, (n,n))\n",
    "    #for each node, decide for one \"next\" node\n",
    "    #for conveniece, we define \"start\" to follow \"end\" to have a cycle\n",
    "    next_node_probs = tf.nn.softmax(next_node_probs)\n",
    "    \n",
    "    model = keras.Model(inputs=[V], \n",
    "                        outputs=[layers.Lambda(lambda x: x, name=\"start_node\")(start_node_probs),\n",
    "                                layers.Lambda(lambda x: x, name=\"next_nodes\")(next_node_probs)])\n",
    "\n",
    "    return model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "serial-sierra",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 5.2243 - start_node_loss: 1.1372 - next_nodes_loss: 4.0870 - start_node_categorical_accuracy: 0.8270 - next_nodes_categorical_accuracy: 0.1359 - val_loss: 4.5623 - val_start_node_loss: 1.3491 - val_next_nodes_loss: 3.2131 - val_start_node_categorical_accuracy: 0.3800 - val_next_nodes_categorical_accuracy: 0.2658\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 2.5028 - start_node_loss: 0.3650 - next_nodes_loss: 2.1378 - start_node_categorical_accuracy: 0.9800 - next_nodes_categorical_accuracy: 0.4389 - val_loss: 2.9392 - val_start_node_loss: 0.4544 - val_next_nodes_loss: 2.4848 - val_start_node_categorical_accuracy: 1.0000 - val_next_nodes_categorical_accuracy: 0.2946\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 1.9618 - start_node_loss: 0.2408 - next_nodes_loss: 1.7210 - start_node_categorical_accuracy: 0.9940 - next_nodes_categorical_accuracy: 0.4693 - val_loss: 2.5724 - val_start_node_loss: 0.2997 - val_next_nodes_loss: 2.2726 - val_start_node_categorical_accuracy: 1.0000 - val_next_nodes_categorical_accuracy: 0.2248\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 1.8095 - start_node_loss: 0.2270 - next_nodes_loss: 1.5825 - start_node_categorical_accuracy: 0.9960 - next_nodes_categorical_accuracy: 0.4775 - val_loss: 2.4724 - val_start_node_loss: 0.3915 - val_next_nodes_loss: 2.0809 - val_start_node_categorical_accuracy: 1.0000 - val_next_nodes_categorical_accuracy: 0.3215\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 1.6577 - start_node_loss: 0.1840 - next_nodes_loss: 1.4736 - start_node_categorical_accuracy: 1.0000 - next_nodes_categorical_accuracy: 0.5047 - val_loss: 2.3277 - val_start_node_loss: 0.2481 - val_next_nodes_loss: 2.0796 - val_start_node_categorical_accuracy: 1.0000 - val_next_nodes_categorical_accuracy: 0.2746\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 1.5119 - start_node_loss: 0.1220 - next_nodes_loss: 1.3899 - start_node_categorical_accuracy: 0.9970 - next_nodes_categorical_accuracy: 0.5292 - val_loss: 2.0490 - val_start_node_loss: 0.1424 - val_next_nodes_loss: 1.9066 - val_start_node_categorical_accuracy: 1.0000 - val_next_nodes_categorical_accuracy: 0.3284\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 1.5215 - start_node_loss: 0.1489 - next_nodes_loss: 1.3726 - start_node_categorical_accuracy: 0.9940 - next_nodes_categorical_accuracy: 0.5401 - val_loss: 2.0168 - val_start_node_loss: 0.1419 - val_next_nodes_loss: 1.8749 - val_start_node_categorical_accuracy: 1.0000 - val_next_nodes_categorical_accuracy: 0.3543\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 1.4213 - start_node_loss: 0.1068 - next_nodes_loss: 1.3145 - start_node_categorical_accuracy: 0.9990 - next_nodes_categorical_accuracy: 0.5624 - val_loss: 1.9110 - val_start_node_loss: 0.1810 - val_next_nodes_loss: 1.7299 - val_start_node_categorical_accuracy: 1.0000 - val_next_nodes_categorical_accuracy: 0.4337\n",
      "Epoch 9/20\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 1.3573 - start_node_loss: 0.0971 - next_nodes_loss: 1.2603 - start_node_categorical_accuracy: 1.0000 - next_nodes_categorical_accuracy: 0.5858 - val_loss: 2.2332 - val_start_node_loss: 0.3338 - val_next_nodes_loss: 1.8994 - val_start_node_categorical_accuracy: 1.0000 - val_next_nodes_categorical_accuracy: 0.3563\n",
      "Epoch 10/20\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 1.3173 - start_node_loss: 0.0855 - next_nodes_loss: 1.2317 - start_node_categorical_accuracy: 1.0000 - next_nodes_categorical_accuracy: 0.5984 - val_loss: 1.8765 - val_start_node_loss: 0.1843 - val_next_nodes_loss: 1.6922 - val_start_node_categorical_accuracy: 1.0000 - val_next_nodes_categorical_accuracy: 0.4503\n",
      "Epoch 11/20\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 1.3130 - start_node_loss: 0.0906 - next_nodes_loss: 1.2224 - start_node_categorical_accuracy: 0.9990 - next_nodes_categorical_accuracy: 0.6059 - val_loss: 1.8985 - val_start_node_loss: 0.1719 - val_next_nodes_loss: 1.7267 - val_start_node_categorical_accuracy: 1.0000 - val_next_nodes_categorical_accuracy: 0.4320\n",
      "Epoch 12/20\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 1.2755 - start_node_loss: 0.0806 - next_nodes_loss: 1.1949 - start_node_categorical_accuracy: 1.0000 - next_nodes_categorical_accuracy: 0.6212 - val_loss: 1.6825 - val_start_node_loss: 0.0926 - val_next_nodes_loss: 1.5900 - val_start_node_categorical_accuracy: 1.0000 - val_next_nodes_categorical_accuracy: 0.5149\n",
      "Epoch 13/20\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 1.2992 - start_node_loss: 0.0847 - next_nodes_loss: 1.2145 - start_node_categorical_accuracy: 0.9990 - next_nodes_categorical_accuracy: 0.6139 - val_loss: 1.7820 - val_start_node_loss: 0.1069 - val_next_nodes_loss: 1.6752 - val_start_node_categorical_accuracy: 1.0000 - val_next_nodes_categorical_accuracy: 0.4665\n",
      "Epoch 14/20\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 1.2052 - start_node_loss: 0.0553 - next_nodes_loss: 1.1499 - start_node_categorical_accuracy: 1.0000 - next_nodes_categorical_accuracy: 0.6412 - val_loss: 1.9231 - val_start_node_loss: 0.0759 - val_next_nodes_loss: 1.8472 - val_start_node_categorical_accuracy: 1.0000 - val_next_nodes_categorical_accuracy: 0.4315\n",
      "Epoch 15/20\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 1.2159 - start_node_loss: 0.0637 - next_nodes_loss: 1.1522 - start_node_categorical_accuracy: 0.9980 - next_nodes_categorical_accuracy: 0.6457 - val_loss: 1.8116 - val_start_node_loss: 0.1357 - val_next_nodes_loss: 1.6759 - val_start_node_categorical_accuracy: 1.0000 - val_next_nodes_categorical_accuracy: 0.4623\n",
      "Epoch 16/20\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 1.1883 - start_node_loss: 0.0642 - next_nodes_loss: 1.1242 - start_node_categorical_accuracy: 0.9970 - next_nodes_categorical_accuracy: 0.6554 - val_loss: 1.8779 - val_start_node_loss: 0.0518 - val_next_nodes_loss: 1.8260 - val_start_node_categorical_accuracy: 1.0000 - val_next_nodes_categorical_accuracy: 0.4362\n",
      "Epoch 17/20\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 1.2142 - start_node_loss: 0.0636 - next_nodes_loss: 1.1506 - start_node_categorical_accuracy: 0.9990 - next_nodes_categorical_accuracy: 0.6453 - val_loss: 1.8997 - val_start_node_loss: 0.0928 - val_next_nodes_loss: 1.8069 - val_start_node_categorical_accuracy: 1.0000 - val_next_nodes_categorical_accuracy: 0.4504\n",
      "Epoch 18/20\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 1.1251 - start_node_loss: 0.0408 - next_nodes_loss: 1.0843 - start_node_categorical_accuracy: 1.0000 - next_nodes_categorical_accuracy: 0.6758 - val_loss: 1.8568 - val_start_node_loss: 0.0452 - val_next_nodes_loss: 1.8117 - val_start_node_categorical_accuracy: 1.0000 - val_next_nodes_categorical_accuracy: 0.4544\n",
      "Epoch 19/20\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 1.1390 - start_node_loss: 0.0602 - next_nodes_loss: 1.0788 - start_node_categorical_accuracy: 0.9950 - next_nodes_categorical_accuracy: 0.6797 - val_loss: 1.9236 - val_start_node_loss: 0.1519 - val_next_nodes_loss: 1.7718 - val_start_node_categorical_accuracy: 1.0000 - val_next_nodes_categorical_accuracy: 0.4868\n",
      "Epoch 20/20\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 1.4490 - start_node_loss: 0.1976 - next_nodes_loss: 1.2514 - start_node_categorical_accuracy: 0.9730 - next_nodes_categorical_accuracy: 0.6168 - val_loss: 1.9092 - val_start_node_loss: 0.1571 - val_next_nodes_loss: 1.7521 - val_start_node_categorical_accuracy: 1.0000 - val_next_nodes_categorical_accuracy: 0.4503\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    \"message_passing_iterations\" : 10,\n",
    "    \"latent_dim\" : 16\n",
    "}\n",
    "\n",
    "NUM_EPOCHS = 20\n",
    "\n",
    "\n",
    "GNN = make_GNN(config)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate = 1e-3)\n",
    "\n",
    "GNN.compile(loss={\"start_node\" : \"categorical_crossentropy\",\n",
    "                  \"next_nodes\" : \"categorical_crossentropy\"}, \n",
    "            optimizer=optimizer, \n",
    "            metrics={\"start_node\" : \"categorical_accuracy\",\n",
    "                     \"next_nodes\" : \"categorical_accuracy\"})\n",
    "\n",
    "#takes ~2min on GPU\n",
    "#note that this is unneccessarily long since we don't use batching\n",
    "#to keep the code simple\n",
    "history = GNN.fit(train_gen,\n",
    "                    validation_data=val_gen,\n",
    "                    epochs = NUM_EPOCHS,\n",
    "                    verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "western-projection",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_graph, _, sort_indices = make_example((20,30))\n",
    "fig = plt.figure(1, figsize=(4, 4))\n",
    "ax = fig.add_subplot()\n",
    "start_node_probs, next_node_probs = GNN(input_graph)\n",
    "plot_numbers(ax, next_node_probs.numpy(), sort_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handed-diary",
   "metadata": {},
   "source": [
    "### Decode a sorted list\n",
    "\n",
    "Start at the predicted start node. Greedily follow to the next unvisited node with highest probabilty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "pharmaceutical-stupid",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unsorted numbers: [0.77582657 0.0762433  0.36435593 0.9758827  0.25454118 0.31118793\n",
      " 0.64610911 0.2750251  0.74613055 0.51478395 0.84502217 0.28713276\n",
      " 0.72261328 0.30016552 0.88454247 0.70968779 0.13840706 0.09063094\n",
      " 0.9038374  0.60916656 0.16198563 0.61216323]\n",
      "sorted numbers: [0.0762433  0.09063094 0.13840706 0.16198563 0.25454118 0.2750251\n",
      " 0.28713276 0.30016552 0.31118793 0.36435593 0.51478395 0.60916656\n",
      " 0.61216323 0.64610911 0.70968779 0.72261328 0.74613055 0.77582657\n",
      " 0.84502217 0.88454247 0.9038374  0.9758827 ]\n"
     ]
    }
   ],
   "source": [
    "def decode_sorting(numbers, start_node_probs, next_node_probs):\n",
    "    print(\"unsorted numbers:\", numbers)\n",
    "    start = np.argmax(start_node_probs)\n",
    "    sort_indices = [start]\n",
    "    unvisited = np.ones(len(numbers))\n",
    "    unvisited[start] = 0\n",
    "    current_node = start\n",
    "    for i in range(len(numbers)-1):\n",
    "        probs = unvisited * next_node_probs[current_node]\n",
    "        current_node = np.argmax(probs)\n",
    "        unvisited[current_node] = 0\n",
    "        sort_indices.append(current_node)\n",
    "    print(\"sorted numbers:\", numbers[sort_indices])\n",
    "\n",
    "decode_sorting(input_graph[\"nodes\"], start_node_probs, next_node_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "black-monaco",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
